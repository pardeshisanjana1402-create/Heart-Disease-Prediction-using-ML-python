{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de8c1ac-6742-4bf0-8516-0e22b5a03acb",
   "metadata": {},
   "source": [
    "#  **Detailed Explanation of Requirements Used in Project**\n",
    "\n",
    "My project performs **data cleaning**, **EDA**, **visualization**, **machine learning modeling**, and **model evaluation**.\n",
    "To complete these tasks, your code uses several Python libraries.\n",
    "Below is a detailed explanation of each one and why it is required.\n",
    "\n",
    "---\n",
    "\n",
    "#  **1. Data Handling Libraries**\n",
    "\n",
    "## **- pandas**\n",
    "\n",
    "**Why used:**\n",
    "Pandas is the main library for handling datasets. It helps you load, clean, and analyze data.\n",
    "\n",
    "**What it does in your project:**\n",
    "\n",
    "* Loads CSV files\n",
    "* Shows dataset summary (`df.info()`, `df.describe()`)\n",
    "* Removes duplicates\n",
    "* Handles missing values\n",
    "* Selects and modifies columns\n",
    "\n",
    "Pandas is essential for almost all steps in data cleaning and EDA.\n",
    "\n",
    "---\n",
    "\n",
    "## **- numpy**\n",
    "\n",
    "**Why used:**\n",
    "Numpy helps with numerical operations. Machine learning models require data in numeric form, and NumPy makes that possible.\n",
    "\n",
    "**What it does in your project:**\n",
    "\n",
    "* Creates arrays\n",
    "* Performs mathematical operations\n",
    "* Supports sklearn models internally\n",
    "\n",
    "indirectly using numpy when working with ML models and data transformations.\n",
    "\n",
    "---\n",
    "\n",
    "# **2. Visualization Libraries**\n",
    "\n",
    "## **- matplotlib**\n",
    "\n",
    "**Why used:**\n",
    "Matplotlib is used for creating basic graphs.\n",
    "\n",
    "**What it does in your project:**\n",
    "\n",
    "* Plots simple graphs\n",
    "* Draws ROC curve\n",
    "* Draws trend lines and custom visualizations\n",
    "\n",
    "Often used alongside seaborn for more detailed plots.\n",
    "\n",
    "---\n",
    "\n",
    "## **- seaborn**\n",
    "\n",
    "**Why used:**\n",
    "Seaborn makes attractive and statistical graphs.\n",
    "\n",
    "**What it does in your project:**\n",
    "\n",
    "* Creates heatmaps\n",
    "* Creates pairplots\n",
    "* Boxplots, histograms, countplots\n",
    "* Helps visualize patterns and correlations\n",
    "\n",
    "Seaborn simplifies and beautifies EDA visualizations.\n",
    "\n",
    "---\n",
    "\n",
    "#  **3. Machine Learning – Scikit-Learn**\n",
    "\n",
    "`scikit-learn` (sklearn) is the **backbone of your ML modeling**.\n",
    "Almost every ML step in your notebook uses a module from sklearn.\n",
    "\n",
    "Below is a detailed breakdown:\n",
    "\n",
    "---\n",
    "\n",
    "## **(A) Model Selection**\n",
    "\n",
    "### **from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score**\n",
    "\n",
    "**Why used:**\n",
    "\n",
    "* `train_test_split` → splits data into training and testing sets\n",
    "* `StratifiedKFold` → performs balanced K-fold cross-validation\n",
    "* `cross_val_score` → checks model performance using multiple folds\n",
    "\n",
    "This ensures model training is **fair, balanced, and accurate**.\n",
    "\n",
    "---\n",
    "\n",
    "## **(B) Data Preprocessing**\n",
    "\n",
    "### **from sklearn.preprocessing import StandardScaler, OneHotEncoder**\n",
    "\n",
    "**Why used:**\n",
    "\n",
    "* `StandardScaler` → normalizes numeric features\n",
    "* `OneHotEncoder` → converts categorical features into numerical format\n",
    "\n",
    "These transformations improve model performance and stability.\n",
    "\n",
    "---\n",
    "\n",
    "## **(C) Handling Missing Data**\n",
    "\n",
    "### **from sklearn.impute import SimpleImputer**\n",
    "\n",
    "**Why used:**\n",
    "\n",
    "* Fills missing values using:\n",
    "\n",
    "  * mean\n",
    "  * median\n",
    "  * most frequent value\n",
    "\n",
    "project uses this in cleaning and modeling pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## **(D) Column Transformations**\n",
    "\n",
    "### **from sklearn.compose import ColumnTransformer**\n",
    "\n",
    "**Why used:**\n",
    "\n",
    "* Applies different preprocessing steps to different columns\n",
    "  Example:\n",
    "\n",
    "  * Scale numeric columns\n",
    "  * Encode categorical columns\n",
    "\n",
    "This modular approach makes preprocessing more organized.\n",
    "\n",
    "---\n",
    "\n",
    "## **(E) Machine Learning Pipeline**\n",
    "\n",
    "### **from sklearn.pipeline import Pipeline**\n",
    "\n",
    "**Why used:**\n",
    "\n",
    "* Combines preprocessing + model into one object\n",
    "* Makes the entire ML workflow clean and reproducible\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Pipeline([\n",
    "    ('preprocess', ColumnTransformer(...)),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **(F) Models Used in Your Project**\n",
    "\n",
    "### **-LogisticRegression**\n",
    "\n",
    "Used as a baseline model for classification.\n",
    "\n",
    "### **-RandomForestClassifier**\n",
    "\n",
    "Used for strong, high-accuracy modeling with tree-based learning.\n",
    "\n",
    "### **-GradientBoostingClassifier**\n",
    "\n",
    "Used for boosting performance using weak learners.\n",
    "\n",
    "### **-SVC (Support Vector Machine)**\n",
    "\n",
    "Used for high-margin separation in classification tasks.\n",
    "\n",
    "These models help you compare and choose the best performer.\n",
    "\n",
    "---\n",
    "\n",
    "###  **4. ML Evaluation Metrics (from sklearn)**\n",
    "\n",
    "Your project evaluates model performance using the following:\n",
    "\n",
    "* **accuracy_score** → Measures correct predictions\n",
    "* **precision_score** → Focuses on how many predicted positives are correct\n",
    "* **recall_score** → Measures how many actual positives were found\n",
    "* **f1_score** → Balance of precision and recall\n",
    "* **roc_auc_score** → Measures classification quality\n",
    "* **roc_curve** → Used to draw ROC curve\n",
    "* **confusion_matrix** → Shows TP, FP, FN, TN\n",
    "\n",
    "All these help analyze which model performs best and why.\n",
    "\n",
    "---\n",
    "\n",
    "##  **5. Model Saving Library**\n",
    "\n",
    "## **joblib**\n",
    "\n",
    "**Why used:**\n",
    "\n",
    "* Saves trained models into a `.pkl` file\n",
    "* Helps reload the model later without training again\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "joblib.dump(model, \"heart_disease_model.pkl\")\n",
    "```\n",
    "\n",
    "This is important for deployment and future use.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Final Requirements List**\n",
    "```\n",
    "pandas\n",
    "numpy\n",
    "matplotlib\n",
    "seaborn\n",
    "scikit-learn\n",
    "joblib\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be738a3-c95b-43f8-888d-733b7a1b3cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
